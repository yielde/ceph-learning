
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Deploying Metadata Servers &#8212; Ceph Documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/ceph.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="Terminology" href="../standby/" />
    <link rel="prev" title="Multiple Ceph File Systems" href="../multifs/" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex/" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../http-routingtable/" title="HTTP Routing Table"
             >routing table</a> |</li>
        <li class="right" >
          <a href="../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../standby/" title="Terminology"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../multifs/" title="Multiple Ceph File Systems"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../">Ceph Documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../" accesskey="U">Ceph File System</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Deploying Metadata Servers</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div id="docubetter" align="right" style="padding: 15px; font-weight: bold;">
    <a href="https://pad.ceph.com/p/Report_Documentation_Bugs">Report a Documentation Bug</a>
  </div>

  
  <div class="admonition note" id="cephfs-add-remote-mds">
<p class="admonition-title">Note</p>
<p>It is highly recommended to use <a class="reference internal" href="../../cephadm/"><span class="doc">Cephadm</span></a> or another Ceph
orchestrator for setting up the ceph cluster. Use this approach only if you
are setting up the ceph cluster manually. If one still intends to use the
manual way for deploying MDS daemons, <a class="reference internal" href="../../cephadm/services/mds/"><span class="doc">MDS Service</span></a> can
also be used.</p>
</div>
<section id="deploying-metadata-servers">
<h1>Deploying Metadata Servers<a class="headerlink" href="#deploying-metadata-servers" title="Permalink to this heading">¶</a></h1>
<p>Each CephFS file system requires at least one MDS. The cluster operator will
generally use their automated deployment tool to launch required MDS servers as
needed.  Rook and ansible (via the ceph-ansible playbooks) are recommended
tools for doing this. For clarity, we also show the systemd commands here which
may be run by the deployment technology if executed on bare-metal.</p>
<p>See <a class="reference external" href="../mds-config-ref">MDS Config Reference</a> for details on configuring metadata servers.</p>
<section id="provisioning-hardware-for-an-mds">
<h2>Provisioning Hardware for an MDS<a class="headerlink" href="#provisioning-hardware-for-an-mds" title="Permalink to this heading">¶</a></h2>
<p>The present version of the MDS is single-threaded and CPU-bound for most
activities, including responding to client requests. An MDS under the most
aggressive client loads uses about 2 to 3 CPU cores. This is due to the other
miscellaneous upkeep threads working in tandem.</p>
<p>Even so, it is recommended that an MDS server be well provisioned with an
advanced CPU with sufficient cores. Development is on-going to make better use
of available CPU cores in the MDS; it is expected in future versions of Ceph
that the MDS server will improve performance by taking advantage of more cores.</p>
<p>The other dimension to MDS performance is the available RAM for caching. The
MDS necessarily manages a distributed and cooperative metadata cache among all
clients and other active MDSs. Therefore it is essential to provide the MDS
with sufficient RAM to enable faster metadata access and mutation. The default
MDS cache size (see also <a class="reference internal" href="../cache-configuration/"><span class="doc">MDS Cache Configuration</span></a>) is 4GB. It is
recommended to provision at least 8GB of RAM for the MDS to support this cache
size.</p>
<p>Generally, an MDS serving a large cluster of clients (1000 or more) will use at
least 64GB of cache. An MDS with a larger cache is not well explored in the
largest known community clusters; there may be diminishing returns where
management of such a large cache negatively impacts performance in surprising
ways. It would be best to do analysis with expected workloads to determine if
provisioning more RAM is worthwhile.</p>
<p>In a bare-metal cluster, the best practice is to over-provision hardware for
the MDS server. Even if a single MDS daemon is unable to fully utilize the
hardware, it may be desirable later on to start more active MDS daemons on the
same node to fully utilize the available cores and memory. Additionally, it may
become clear with workloads on the cluster that performance improves with
multiple active MDS on the same node rather than over-provisioning a single
MDS.</p>
<p>Finally, be aware that CephFS is a highly-available file system by supporting
standby MDS (see also <a class="reference internal" href="../standby/#mds-standby"><span class="std std-ref">Terminology</span></a>) for rapid failover. To get a real
benefit from deploying standbys, it is usually necessary to distribute MDS
daemons across at least two nodes in the cluster. Otherwise, a hardware failure
on a single node may result in the file system becoming unavailable.</p>
<p>Co-locating the MDS with other Ceph daemons (hyperconverged) is an effective
and recommended way to accomplish this so long as all daemons are configured to
use available hardware within certain limits.  For the MDS, this generally
means limiting its cache size.</p>
</section>
<section id="adding-an-mds">
<h2>Adding an MDS<a class="headerlink" href="#adding-an-mds" title="Permalink to this heading">¶</a></h2>
<ol class="arabic">
<li><p>Create an mds directory <code class="docutils literal notranslate"><span class="pre">/var/lib/ceph/mds/ceph-${id}</span></code>. The daemon only uses this directory to store its keyring.</p></li>
<li><p>Create the authentication key, if you use CephX:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sudo ceph auth get-or-create mds.${id} mon &#39;profile mds&#39; mgr &#39;profile mds&#39; mds &#39;allow *&#39; osd &#39;allow *&#39; &gt; /var/lib/ceph/mds/ceph-${id}/keyring
</pre></div>
</div>
</li>
<li><p>Start the service:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sudo systemctl start ceph-mds@${id}
</pre></div>
</div>
</li>
<li><p>The status of the cluster should show:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>mds: ${id}:1 {0=${id}=up:active} 2 up:standby
</pre></div>
</div>
</li>
<li><p>Optionally, configure the file system the MDS should join (<a class="reference internal" href="../standby/#mds-join-fs"><span class="std std-ref">Configuring MDS file system affinity</span></a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph config set mds.${id} mds_join_fs ${fs}
</pre></div>
</div>
</li>
</ol>
</section>
<section id="removing-an-mds">
<h2>Removing an MDS<a class="headerlink" href="#removing-an-mds" title="Permalink to this heading">¶</a></h2>
<p>If you have a metadata server in your cluster that you’d like to remove, you may use
the following method.</p>
<ol class="arabic">
<li><p>(Optionally:) Create a new replacement Metadata Server. If there are no
replacement MDS to take over once the MDS is removed, the file system will
become unavailable to clients.  If that is not desirable, consider adding a
metadata server before tearing down the metadata server you would like to
take offline.</p></li>
<li><p>Stop the MDS to be removed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sudo systemctl stop ceph-mds@${id}
</pre></div>
</div>
<p>The MDS will automatically notify the Ceph monitors that it is going down.
This enables the monitors to perform instantaneous failover to an available
standby, if one exists. It is unnecessary to use administrative commands to
effect this failover, e.g. through the use of <code class="docutils literal notranslate"><span class="pre">ceph</span> <span class="pre">mds</span> <span class="pre">fail</span> <span class="pre">mds.${id}</span></code>.</p>
</li>
<li><p>Remove the <code class="docutils literal notranslate"><span class="pre">/var/lib/ceph/mds/ceph-${id}</span></code> directory on the MDS.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ sudo rm -rf /var/lib/ceph/mds/ceph-${id}
</pre></div>
</div>
</li>
</ol>
</section>
</section>



            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../">
              <img class="logo" src="../../_static/logo.png" alt="Logo"/>
            </a></p>
<h3><a href="../../">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../start/intro/">Intro to Ceph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/">Installing Ceph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cephadm/">Cephadm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rados/">Ceph Storage Cluster</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../">Ceph File System</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../#getting-started-with-cephfs">Getting Started with CephFS</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../#administration">Administration</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../createfs/"> Create a CephFS file system</a></li>
<li class="toctree-l3"><a class="reference internal" href="../administration/"> Administrative commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../multifs/"> Creating Multiple File Systems</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#"> Provision/Add/Remove MDS(s)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#provisioning-hardware-for-an-mds">Provisioning Hardware for an MDS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#adding-an-mds">Adding an MDS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#removing-an-mds">Removing an MDS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../standby/">Terminology</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standby/#referring-to-mds-daemons">Referring to MDS daemons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standby/#managing-failover">Managing failover</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standby/#configuring-standby-replay">Configuring standby-replay</a></li>
<li class="toctree-l3"><a class="reference internal" href="../standby/#configuring-mds-file-system-affinity">Configuring MDS file system affinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cache-configuration/"> MDS Cache Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mds-config-ref/"> MDS Configuration Settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../man/8/ceph-mds/"> Manual: ceph-mds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nfs/"> Export over NFS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../app-best-practices/"> Application best practices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../fs-volumes/"> FS volume and subvolumes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quota/"> CephFS Quotas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../health-messages/"> Health messages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../upgrading/">Upgrading the MDS Cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="../upgrading/#upgrading-pre-firefly-file-systems-past-jewel">Upgrading pre-Firefly file systems past Jewel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cephfs-top/"> CephFS Top Utility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snap-schedule/"> Scheduled Snapshots</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cephfs-mirroring/"> CephFS Snapshot Mirroring</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../#mounting-cephfs">Mounting CephFS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../#cephfs-concepts">CephFS Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../#troubleshooting-and-disaster-recovery">Troubleshooting and Disaster Recovery</a></li>
<li class="toctree-l2"><a class="reference internal" href="../#developer-guides">Developer Guides</a></li>
<li class="toctree-l2"><a class="reference internal" href="../#additional-details">Additional Details</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../rbd/">Ceph Block Device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../radosgw/">Ceph Object Gateway</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mgr/">Ceph Manager Daemon</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mgr/dashboard/">Ceph Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture/">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/developer_guide/">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/internals/">Ceph Internals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../governance/">Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../foundation/">Ceph Foundation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ceph-volume/">ceph-volume</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.ceph.com/en/latest/releases/general/">Ceph Releases (general)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.ceph.com/en/latest/releases/">Ceph Releases (index)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../security/">Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary/">Glossary</a></li>
</ul>


<!-- ugly kludge to make genindex look like it's part of the toc -->
<ul style="margin-top: -10px"><li class="toctree-l1"><a class="reference internal" href="../../genindex/">Index</a></li></ul>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search/" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex/" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../http-routingtable/" title="HTTP Routing Table"
             >routing table</a> |</li>
        <li class="right" >
          <a href="../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../standby/" title="Terminology"
             >next</a> |</li>
        <li class="right" >
          <a href="../multifs/" title="Multiple Ceph File Systems"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../">Ceph Documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../" >Ceph File System</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Deploying Metadata Servers</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Ceph authors and contributors. Licensed under Creative Commons Attribution Share Alike 3.0 (CC-BY-SA-3.0).
    </div>
  </body>
</html>